---
title: "The Manner of People in Exercise"
subtitle: "Practical Machine Learning Course Project"
author: "Xinchun Tian"
output: html_document
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

# Context
In this project, using the personal activity data collected by devices such as Jawbone Up, Nike FuelBand, and Fitbit, from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, we are going to quantify how well people do a particular activity.

Load the packages that will be used in this analysis.
```{r}
suppressPackageStartupMessages(library(AppliedPredictiveModeling))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(rattle))
suppressPackageStartupMessages(library(rpart.plot))
suppressPackageStartupMessages(library(randomForest))
```

# Getting and Cleaning the data (training + testing)
```{r}
if (!file.exists("pml-training.csv")) {
    url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    download.file(url, destfile="./pml-training.csv", method="curl")
    dateDownloaded <- date()
}
if (!file.exists("pml-testing.csv")) {
    url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(url, destfile="./pml-testing.csv", method="curl")
    dateDownloaded <- date()
}
```

```{r}
# read in the data sets, both training and testing
training <- read.csv("pml-training.csv", na.strings=c("NA","","#DIV/0!"), sep=",")
testing  <- read.csv("pml-testing.csv",  na.strings=c("NA","","#DIV/0!"), sep=",")
# subset the data and keeps rows from 8 to the end
training <- training[,c(8:160)]
testing  <- testing[,c(8:160)]
# only keep the rows with less than 50% of missing values
col_to_keep = c()
for (i in 1:dim(training)[2]) {
  if ((sum(is.na(training[,i]))/nrow(training))<0.5) {
    col_to_keep <- append(col_to_keep, i)
  }
}
training <- training[,col_to_keep]
testing  <- testing[,col_to_keep]
dim(training)
dim(testing)
```
The idea is that if the fraction of missing values of a column is great than 50%, we will drop this column for downstream analysis. After the cleaning, there are 53 columns left including the outcome column "classe". A further check has been done and found no missing values in the tidy data so there is no need to impute the training and testing data set.

```{r}
set.seed(123)
inTrain <- createDataPartition(y=training$classe, p=0.5, list=FALSE)
training0 <- training[inTrain,]
training1 <- training[-inTrain,]
```

Let us plot the variables to check their distributions, and if the distributions have skewed shapes, we have to preprocess them (See appendix).
```{r}
par(mfrow=c(4,4))
par(mai=c(0.6,0.6,0,0))
tnames <- names(training)
for (i in 1:52) {
  hist(training[,i], xlab=tnames[i], breaks=20, col="lightblue", main="")
}
```

The plots show that many features are not normally distributed, so we have to apply proprocessing upon them.
```{r}
par(mfrow=c(4,4))
par(mai=c(0.6,0.6,0,0))
preProTraining   <- preProcess(training0[,-53], method=c("center","scale"))
predictTraining  <- predict(preProTraining, training0[,-53])
for (i in 1:52) {
  hist(predictTraining[,i], xlab=tnames[i], breaks=20, col="lightblue", main="")
}
```

```{r}
#set.seed(666)
#modFit <- train(training0$classe ~ .,  preProcess=c("center", "scale"), trControl=trainControl(method = "cv", number = 4), data = training0, method="rpart")
#predictions <- predict(modFit, newdata=training1)
#print(confusionMatrix(predictions, training1$classe), digits=4)
```


```{r}
set.seed(666)
trainControl <- trainControl(method="cv", number = 5)
modelFit     <- train(training0$classe ~ ., data = predictTraining, trControl=trainControl, preProcess="pca",  method="rpart")
testFit      <- predict(predictTraining, training1[,-53])

#print (confusionMatrix(training1$classe, predict(modelFit, testFit)))
```